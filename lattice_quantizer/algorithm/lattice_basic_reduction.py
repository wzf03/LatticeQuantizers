import numpy as np


def dot_product(vec1, vec2):
    """
    Dot product of two vectors.
    """
    return sum(x1 * x2 for x1, x2 in zip(vec1, vec2))


def check_orthogonality(vec1, vec2):
    """
    Checks for orthogonality given 2 vectors by computing dot product. Used in
    test cases for Gram-Schmidt.
    """
    if dot_product(vec1, vec2) == 0:
        return True
    return False


def gramschmidt(V):
    """
    Gram-Schmidt algorithm. Takes in a basis and returns an orthogonal basis.
    Based on pseudo-code HPS 7.3.
    """

    def projection(u, v):  # helper for GS
        return (dot_product(u, v) / dot_product(u, u)) * np.array(u)

    U = []  # orthogonalized basis

    for v in V:
        temp = np.array(v)
        # for u in U:
        #     temp = np.array(temp) - projection(u, v)
        sum_u = 0
        for u in U:
            sum_u += projection(u, v)
        temp = np.array(temp) - sum_u

        if np.any(temp):
            U.append(temp.tolist())

    return U


def red_(basis):
    n = len(basis)
    k = 1

    o_basis = gramschmidt(basis)

    def coef(i, j):  # helper for LLL
        return dot_product(basis[i], o_basis[j]) / dot_product(o_basis[j], o_basis[j])

    iter = 0
    while k < n:
        # iter+=1
        for j in range(k - 1, -1, -1):
            # Reduction step
            mu1 = coef(k, j)
            if abs(mu1) > 0.5:
                basis[k] = np.array(basis[k]) - (round(mu1) * np.array(basis[j]))

                o_basis = gramschmidt(basis)

        # Check for Lovász Condition
        mu2 = coef(k, k - 1)
        if dot_product(o_basis[k], o_basis[k]) >= (0.75 - pow(mu2, 2)) * dot_product(
            o_basis[k - 1], o_basis[k - 1]
        ):
            k += 1
        else:
            # Swap step
            tmp = basis[k]
            basis[k] = basis[k - 1]
            basis[k - 1] = tmp
            o_basis = gramschmidt(basis)
            k = max(k - 1, 1)
        if iter == 10:
            break

    return basis


def red(B, delta=0.75):
    """
    The reduction function RED(B) returns another generator matrix for the
    lattice generated by B, in which the rows (basis vectors) are shorter and
    more orthogonal to each other than in B. If no improved generator matrix is
    found, B is returned unchanged. A fast and popular algorithm for the purpose
    is the Lenstra-Lenstra-Lov ́asz algorithm [24, Fig. 1], which we apply in
    this work. In the context of (2), reduction corresponds to finding a suitable U .
    """
    """
    Computes LLL reduction algorithm on a given basis.
    Based on pseudo-code HPS 7.13.
    """

    B = B.astype(float)
    m, n = B.shape

    # Gram-Schmidt initialization
    def gram_schmidt(B):
        B_star = np.zeros_like(B)
        mu = np.zeros((n, n))
        for i in range(n):
            B_star[:, i] = B[:, i]
            for j in range(i):
                mu[i, j] = np.dot(B[:, i], B_star[:, j]) / np.dot(
                    B_star[:, j], B_star[:, j]
                )
                B_star[:, i] -= mu[i, j] * B_star[:, j]
        return B_star, mu

    B_star, mu = gram_schmidt(B)
    k = 1
    while k < n:
        # Size reduction
        for j in range(k - 1, -1, -1):
            r = round(mu[k, j])
            if r != 0:
                B[:, k] -= r * B[:, j]
                for l in range(j + 1):
                    mu[k, l] -= r * mu[j, l]
                B_star[:, k] -= r * B_star[:, j]

        # Lovasz condition
        if np.dot(B_star[:, k], B_star[:, k]) >= (delta - mu[k, k - 1] ** 2) * np.dot(
            B_star[:, k - 1], B_star[:, k - 1]
        ):
            k += 1
        else:
            B[:, [k, k - 1]] = B[:, [k - 1, k]]
            B_star, mu = gram_schmidt(B)
            k = max(k - 1, 1)
    return B
